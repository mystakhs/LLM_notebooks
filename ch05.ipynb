{
    "cells": [
     {
      "cell_type": "markdown",
      "id": "45398736-7e89-4263-89c8-92153baff553",
      "metadata": {},
      "source": [
       "<table style=\"width:100%\">\n",
       "<tr>\n",
       "<td style=\"vertical-align:middle; text-align:left;\">\n",
       "<font size=\"2\">\n",
       "<a href=\"http://mng.bz/orYv\">『Build a Large Language Model From Scratch』</a>書籍（著者 <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a>）向けの補足コードである<br>\n",
       "<br>コードリポジトリ: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
       "</font>\n",
       "</td>\n",
       "<td style=\"vertical-align:middle; text-align:left;\">\n",
       "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "66dd524e-864c-4012-b0a2-ccfc56e80024",
      "metadata": {
       "id": "66dd524e-864c-4012-b0a2-ccfc56e80024"
      },
      "source": [
       "# 第5章: ラベルなしデータでの事前学習"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 1,
      "id": "92b989e9-da36-4159-b212-799184764dd9",
      "metadata": {},
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "matplotlib version: 3.10.1\n",
         "numpy version: 2.0.2\n",
         "tiktoken version: 0.9.0\n",
         "torch version: 2.6.0\n",
         "tensorflow version: 2.18.0\n"
        ]
       }
      ],
      "source": [
       "from importlib.metadata import version\n",
       "\n",
       "pkgs = [\"matplotlib\", \n",
       "        \"numpy\", \n",
       "        \"tiktoken\", \n",
       "        \"torch\",\n",
       "        \"tensorflow\" # For OpenAI's pretrained weights\n",
       "       ]\n",
       "for p in pkgs:\n",
       "    print(f\"{p} version: {version(p)}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "0a3bdf9e-2ff0-4a57-abab-ede2d955a237",
      "metadata": {},
      "source": [
       "- 本章では、基本的なモデル評価に関するコードや学習ループを実装し、LLMを事前学習させる方法を示すである\n",
       "- 本章の最後では、OpenAIから公開されている事前学習済みの重みをモデルに読み込む方法も示すである"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "efd27fcc-2886-47cb-b544-046c2c31f02a",
      "metadata": {},
      "source": [
       "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/chapter-overview.webp\" width=500px>"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "0d214765-7a73-42d5-95e9-302154b29db9",
      "metadata": {},
      "source": [
       "- 本章で扱うトピックは下図のとおりである"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "f67711d4-8391-4fee-aeef-07ea53dd5841",
      "metadata": {},
      "source": [
       "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model--0.webp\" width=400px>"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "0d824183-145c-4865-89e1-1f0d0a338f19",
      "metadata": {
       "id": "0d824183-145c-4865-89e1-1f0d0a338f19"
      },
      "source": [
       "## 5.1 生成的テキストモデルの評価"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "a3350f8c-5181-4f9b-a789-4523105e98f2",
      "metadata": {},
      "source": [
       "- まずは、前章のコードを使ってGPTモデルを初期化する手順を簡単におさらいするである\n",
       "- 次に、LLMに対する基本的な評価指標について議論するである\n",
       "- そして最後に、これらの評価指標を学習用および検証用データセットに適用するである"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd",
      "metadata": {
       "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd"
      },
      "source": [
       "### 5.1.1 GPTを用いたテキスト生成"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "5b3415fd-9f4a-4548-908e-9dfa56edc9bc",
      "metadata": {},
      "source": [
       "- 前章のコードを用いてGPTモデルを初期化するである"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 2,
      "id": "86000d74-624a-48f0-86da-f41926cb9e04",
      "metadata": {
       "colab": {
        "base_uri": "https://localhost:8080/"
       },
       "id": "86000d74-624a-48f0-86da-f41926cb9e04",
       "outputId": "ad482cfd-5a62-4f0d-e1e0-008d6457f512"
      },
      "outputs": [],
      "source": [
       "import torch\n",
       "from previous_chapters import GPTModel\n",
       "# If the `previous_chapters.py` file is not available locally,\n",
       "# you can import it from the `llms-from-scratch` PyPI package.\n",
       "# For details, see: https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n",
       "# E.g.,\n",
       "# from llms_from_scratch.ch04 import GPTModel\n",
       "\n",
       "GPT_CONFIG_124M = {\n",
       "    \"vocab_size\": 50257,   # Vocabulary size\n",
       "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
       "    \"emb_dim\": 768,        # Embedding dimension\n",
       "    \"n_heads\": 12,         # Number of attention heads\n",
       "    \"n_layers\": 12,        # Number of layers\n",
       "    \"drop_rate\": 0.1,      # Dropout rate\n",
       "    \"qkv_bias\": False      # Query-key-value bias\n",
       "}\n",
       "\n",
       "torch.manual_seed(123)\n",
       "model = GPTModel(GPT_CONFIG_124M)\n",
       "model.eval();  # Disable dropout during inference"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "09c6cf0f-7458-48a2-97fd-aa5068d65e8c",
      "metadata": {},
      "source": [
       "- 上ではドロップアウトに0.1を設定しているが、近年のLLMの学習ではドロップアウトなしにするケースも比較的多いである\n",
       "- また、最新のLLMではクエリ、キー、バリュー行列を作る`nn.Linear`層でバイアスを使用しないことも一般的であり（初期のGPTモデルとは異なる）、`\"qkv_bias\": False`がそれに対応しているである\n",
       "- `context_length`は計算資源を節約するために256トークンに減らしている（本来のGPT-2 124Mパラメータ版では1024トークン）\n",
       "  - これは多くの読者がノートPCでもコードを実行できるように配慮しているである\n",
       "  - ただし、`context_length`を1024に戻すことも自由である（その場合、コードの変更は不要である）\n",
       "  - また本章の最後では、`context_length`が1024のモデルを事前学習済みの重みから読み込む方法も示すである"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "59f80895-be35-4bb5-81cb-f357ef7367fe",
      "metadata": {},
      "source": [
       "- 次に、前章で定義した`generate_text_simple`関数を用いてテキストを生成するである\n",
       "- さらに、トークンIDとテキストを相互変換するための便利な関数`text_to_token_ids`と`token_ids_to_text`を定義し、本章全体で使用するである"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "741881f3-cee0-49ad-b11d-b9df3b3ac234",
      "metadata": {},
      "source": [
       "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/gpt-process.webp\" width=500px>"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5e062b82-3540-48ce-8eb4-009686d0d16c",
      "metadata": {},
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Output text:\n",
         " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
        ]
       }
      ],
      "source": [
       "import tiktoken\n",
       "from previous_chapters import generate_text_simple\n",
       "\n",
       "# Alternatively:\n",
       "# from llms_from_scratch.ch04 import generate_text_simple\n",
       "\n",
       "def text_to_token_ids(text, tokenizer):\n",
       "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
       "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
       "    return encoded_tensor\n",
       "\n",
       "def token_ids_to_text(token_ids, tokenizer):\n",
       "    flat = token_ids.squeeze(0) # remove batch dimension\n",
       "    return tokenizer.decode(flat.tolist())\n",
       "\n",
       "start_context = \"Every effort moves you\"\n",
       "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
       "\n",
       "token_ids = generate_text_simple(\n",
       "    model=model,\n",
       "    idx=text_to_token_ids(start_context, tokenizer),\n",
       "    max_new_tokens=10,\n",
       "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
       ")\n",
       "\n",
       "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "e4d3249b-b2a0-44c4-b589-ae4b403b8305",
      "metadata": {},
      "source": [
       "- 上記の通り、モデルはまだ学習されていないため、まともな文章は出力されないである\n",
       "- では、どのようにしてモデルが出力した文章の「良さ」を数値的に把握し、学習の進捗を追跡できるようにするか\n",
       "- 次節では、そのために用いる生成出力に対する損失（ロス）を測る指標について説明するである\n",
       "- また、次章で扱うLLMのファインチューニングでは、ここで示す以外の方法でモデル品質を測る方法も示すである"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "955f9e1a-7bf7-40d8-b1fa-eacabdee8d8e",
      "metadata": {},
      "source": [
       "<br>"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98",
      "metadata": {
       "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98"
      },
      "source": [
       "### 5.1.2 テキスト生成ロスの計算: クロスエントロピーとパープレキシティ"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "9e1ba8aa-fb03-4d25-957f-fe8778762440",
      "metadata": {},
      "source": [
       "- 2つの学習例（行）を含むトークンIDの`inputs`テンソルがあるとする\n",
       "- それに対応する目的のトークンIDを`targets`とし、モデルに生成してほしいトークン列を保持している\n",
       "- 先述の通り、`targets`は`inputs`を1トークン分シフトしたものである（これは第2章でデータローダを実装した際に説明した）"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f",
      "metadata": {
       "colab": {
        "base_uri": "https://localhost:8080/"
       },
       "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f",
       "outputId": "8d6fa0ff-7b37-4634-c3f0-2c050cbe81f0"
      },
      "outputs": [],
      "source": [
       "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
       "                       [40,    1107, 588]])   #  \"I really like\"]\n",
       "\n",
       "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
       "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "33dc0645-ac2c-4973-9b40-6da40515bede",
      "metadata": {},
      "source": [
       "- `inputs`をモデルに与えると、2つの入力例それぞれについて3トークンぶんのロジット（vocab_size=50,257次元）を得る\n",
       "- ソフトマックスを適用すると、同じ次元のテンソルとして確率スコアを得ることができるである"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e7b6ec51-6f8c-49bd-a349-95ba38b46fb6",
      "metadata": {},
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "torch.Size([2, 3, 50257])\n"
        ]
       }
      ],
      "source": [
       "with torch.no_grad():\n",
       "    logits = model(inputs)\n",
       "\n",
       "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
       "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "5c36a382-b5e2-4de6-9e65-0b69b685013b",
      "metadata": {},
      "source": [
       "- 下図は非常に小さい語彙サイズで例示しているが、前章末尾で議論したように、この確率スコアからテキストを復元する流れを図示したものである"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "384d86a9-0013-476c-bb6b-274fd5f20b29",
      "metadata": {},
      "source": [
       "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/proba-to-text.webp\" width=500px>"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "e8480efd-d419-4954-9ecc-2876055334bd",
      "metadata": {},
      "source": [
       "- 前章で述べたように、ソフトマックスで得られた確率スコアに`argmax`を適用すれば予測トークンIDを得られるである\n",
       "- これは50,257次元の確率スコアの中で最も値が大きい要素の位置が予測トークンIDを表す"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "f3b84c9f-dd08-482e-b903-a86fe44e1144",
      "metadata": {},
      "source": [
       "- 2つの入力バッチに対して3トークン分あるので、2×3の予測トークンIDを得ることになるである:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 6,
      "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
      "metadata": {
       "colab": {
        "base_uri": "https://localhost:8080/"
       },
       "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
       "outputId": "ed17da47-c3e7-4775-fd00-4ec5bcda3db2"
      },
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Token IDs:\n",
         " tensor([[[16657],\n",
         "         [  339],\n",
         "         [42826]],\n",
         "\n",
         "        [[49906],\n",
         "         [29669],\n",
         "         [41751]]])\n"
        ]
       }
      ],
      "source": [
       "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
       "print(\"Token IDs:\\n\", token_ids)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "cee4072c-21ed-4df7-8721-dd2535362573",
      "metadata": {},
      "source": [
       "- これらのトークンをデコードしてみると、`targets`とは全く異なるものになっているのがわかる（まだ学習前なので当然である）:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c990ead6-53cd-49a7-a6d1-14d8c1518249",
      "metadata": {},
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Targets batch 1:  effort moves you\n",
         "Outputs batch 1:  Armed heNetflix\n"
        ]
       }
      ],
      "source": [
       "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
       "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "a53eb8a7-070e-46d6-930c-314ba55a6ff2",
      "metadata": {},
      "source": [
       "- これはまだ学習が行われていないためである\n",
       "- モデルの重みを最適化するには、予測結果が正解（targets）からどれだけ離れているかを測る必要がある"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "ad90592f-0d5d-4ec8-9ff5-e7675beab10e",
      "metadata": {},
      "source": [
       "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/proba-index.webp\" width=500px>"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "c7251bf5-a079-4782-901d-68c9225d3157",
      "metadata": {},
      "source": [
       "- 下記のように、ターゲットに対応するトークンの確率だけを取り出すことができるである:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 8,
      "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
      "metadata": {
       "colab": {
        "base_uri": "https://localhost:8080/"
       },
       "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
       "outputId": "41c946a2-c458-433e-a53d-5e7e89d9dddc"
      },
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
         "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
        ]
       }
      ],
      "source": [
       "text_idx = 0\n",
       "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
       "print(\"Text 1:\", target_probas_1)\n",
       "\n",
       "text_idx = 1\n",
       "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
       "print(\"Text 2:\", target_probas_2)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "a0e89a19-73c2-4e49-93b4-861f699f1cbf",
      "metadata": {},
      "source": [
       "- これらの値をできるだけ1に近づけたい（最大化したい）\n",
       "- ただし、数学的な最適化の観点からは、確率スコアそのものよりも対数（log）を最大化したほうが扱いやすい\n",
       "- 詳細は本書の範囲外だが、より深く知りたい場合は、私が録画した講義[L8.2 Logistic Regression Loss Function](https://www.youtube.com/watch?v=GxJe0DZvydM)を参照してほしい"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 9,
      "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
      "metadata": {
       "colab": {
        "base_uri": "https://localhost:8080/"
       },
       "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
       "outputId": "1bf18e79-1246-4eab-efd8-12b328c78678"
      },
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
        ]
       }
      ],
      "source": [
       "# Compute logarithm of all token probabilities\n",
       "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
       "print(log_probas)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "c4261441-a511-4633-9c4c-67998af31b84",
      "metadata": {},
      "source": [
       "- 次に、これらの平均値をとってみる:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9b003797-161b-4d98-81dc-e68320e09fec",
      "metadata": {
       "colab": {
        "base_uri": "https://localhost:8080/"
       },
       "id": "9b003797-161b-4d98-81dc-e68320e09fec",
       "outputId": "a447fe9c-7e27-40ed-f1fb-51210e3f7cc9"
      },
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "tensor(-10.7940)\n"
        ]
       }
      ],
      "source": [
       "# Calculate the average probability for each token\n",
       "avg_log_probas = torch.mean(log_probas)\n",
       "print(avg_log_probas)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "36d51994-ad17-4ba3-a6ec-f588b4b13585",
      "metadata": {},
      "source": [
       "- これはできるだけ0に近づけたい値であり、現状はまだまだ小さい（マイナスが大きい）\n",
       "- 実際の学習では、この対数確率の平均値を最大化するのではなく、**負**にした平均値を**最小化**する形にするのが深層学習の慣例である\n",
       "- -10.7722を大きくしようとする（0に近づける）代わりに、10.7722を小さくしようとする（0に近づける）わけである\n",
       "- 負の平均対数確率の値は、深層学習においてはクロスエントロピー損失とも呼ばれる"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 11,
      "id": "176ddf35-1c5f-4d7c-bf17-70f3e7069bd4",
      "metadata": {},
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "tensor(10.7940)\n"
        ]
       }
      ],
      "source": [
       "neg_avg_log_probas = avg_log_probas * -1\n",
       "print(neg_avg_log_probas)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "84eeb868-abd8-4028-82db-107546bf7c2c",
      "metadata": {},
      "source": [
       "- PyTorchにはすでに`cross_entropy`という関数が実装されており、上記のステップをまとめて自動で実行してくれる"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "5bd24b7f-b760-47ad-bc84-86d13794aa54",
      "metadata": {},
      "source": [
       "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/cross-entropy.webp?123\" width=400px>"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "e8aaf9dd-3ee6-42bf-a63f-6e93dbfb989d",
      "metadata": {},
      "source": [
       "- まず`logits`と`targets`の形状を確認しておく:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 12,
      "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
      "metadata": {
       "colab": {
        "base_uri": "https://localhost:8080/"
       },
       "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
       "outputId": "43fd802a-8136-4b35-df0d-f61a5d4cb561"
      },
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Logits shape: torch.Size([2, 3, 50257])\n",
         "Targets shape: torch.Size([2, 3])\n"
        ]
       }
      ],
      "source": [
       "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
       "print(\"Logits shape:\", logits.shape)\n",
       "\n",
       "# Targets have shape (batch_size, num_tokens)\n",
       "print(\"Targets shape:\", targets.shape)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "1d3d65f0-6566-4865-93e4-0c0bcb10cd06",
      "metadata": {},
      "source": [
       "- PyTorchの`cross_entropy`を使うには、これらのテンソルをバッチ次元でフラット化する必要がある:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0e17e027-ab9f-4fb5-ac9b-a009b831c122",
      "metadata": {
       "colab": {
        "base_uri": "https://localhost:8080/"
       },
       "id": "0e17e027-ab9f-4fb5-ac9b-a009b831c122",
       "outputId": "0b2b778b-02fb-43b2-c879-adc59055a7d8"
      },
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Flattened logits: torch.Size([6, 50257])\n",
         "Flattened targets: torch.Size([6])\n"
        ]
       }
      ],
      "source": [
       "logits_flat = logits.flatten(0, 1)\n",
       "targets_flat = targets.flatten()\n",
       "\n",
       "print(\"Flattened logits:\", logits_flat.shape)\n",
       "print(\"Flattened targets:\", targets_flat.shape)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "4921a57f-3a79-473e-a863-6d63b495010f",
      "metadata": {},
      "source": [
       "- `targets`はトークンID（索引）なので、ロジットの中の対応する位置を最大化したいわけである\n",
       "- `cross_entropy`はソフトマックスと対数の計算も内部でまとめて行ってくれる"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 14,
      "id": "62d0816e-b29a-4c8f-a9a5-a167562de978",
      "metadata": {
       "colab": {
        "base_uri": "https://localhost:8080/"
       },
       "id": "62d0816e-b29a-4c8f-a9a5-a167562de978",
       "outputId": "c0be634a-2c65-4ff7-a73f-1bfc2e406ba4"
      },
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "tensor(10.7940)\n"
        ]
       }
      ],
      "source": [
       "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
       "print(loss)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "0f15ce17-fd7b-4d8e-99da-b237523a7a80",
      "metadata": {},
      "source": [
       "- クロスエントロピーと関連する概念としてパープレキシティがある\n",
       "- パープレキシティはクロスエントロピーを指数変換したものに相当する"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 15,
      "id": "168952a1-b964-4aa7-8e49-966fa26add54",
      "metadata": {
       "colab": {
        "base_uri": "https://localhost:8080/"
       },
       "id": "168952a1-b964-4aa7-8e49-966fa26add54",
       "outputId": "a0a692c1-6412-4068-8aa5-8858548141eb"
      },
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "tensor(48725.8203)\n"
        ]
       }
      ],
      "source": [
       "perplexity = torch.exp(loss)\n",
       "print(perplexity)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "71ae26dd-d77e-41fd-b924-6bd103dd4ee7",
      "metadata": {},
      "source": [
       "- パープレキシティは、各ステップでモデルが不確かな有効語彙サイズとして理解することもできる（例では48,725程度）\n",
       "- より具体的には、モデルが実際の単語分布とどの程度合っているかを示す指標で、値が小さいほど良い予測をしているといえる"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487",
      "metadata": {
       "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487"
      },
      "source": [
       "### 5.1.3 学習セットと検証セットのロスを計算する"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "530da89e-2448-436c-8f1b-28e8a31ef85c",
      "metadata": {},
      "source": [
       "- 以下では、非常に小規模なデータセット（1つの短編ストーリーのみ）でLLMを学習させる\n",
       "- 理由は以下の通りである:\n",
       "  - ノートPCなどGPU環境が必須でない場面でも実行しやすい\n",
       "  - 学習が（数分で）すぐ終わるため、教育目的に適している\n",
       "  - 公共のドメインにある文章を使用することで、著作権上の問題がなく、かつリポジトリ容量を大きくしすぎることを避けられる\n",
       "\n",
       "- 参考までに、Llama 2 7Bは2兆トークンをA100 GPUで184,320 GPU時間かけて学習されたとされる\n",
       "  - この時点でのAWSの8xA100サーバは1時間あたりおよそ30ドルほどかかる\n",
       "  - ざっくり計算すると、(184,320 / 8) × 30ドル = 690,000ドル弱になる\n",
       "\n",
       "- 以下では第2章で使用したのと同じデータセットを使用するである"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 16,
      "id": "654fde37-b2a9-4a20-a8d3-0206c056e2ff",
      "metadata": {},
      "outputs": [],
      "source": [
       "import os\n",
       "import urllib.request\n",
       "\n",
       "file_path = \"the-verdict.txt\"\n",
       "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
       "\n",
       "if not os.path.exists(file_path):\n",
       "    with urllib.request.urlopen(url) as response:\n",
       "        text_data = response.read().decode('utf-8')\n",
       "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
       "        file.write(text_data)\n",
       "else:\n",
       "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
       "        text_data = file.read()"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "379330f1-80f4-4e34-8724-41d892b04cee",
      "metadata": {},
      "source": [
       "- テキストが正しく読み込まれたか、先頭と末尾の100文字ほどを確認してみるである"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6kgJbe4ehI4q",
      "metadata": {
       "colab": {
        "base_uri": "https://localhost:8080/",
        "height": 35
       },
       "id": "6kgJbe4ehI4q",
       "outputId": "9ff31e88-ee37-47e9-ee64-da6eb552f46f"
      },
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
        ]
       }
      ],
      "source": [
       "# First 100 characters\n",
       "print(text_data[:99])"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 18,
      "id": "j2XPde_ThM_e",
      "metadata": {
       "colab": {
        "base_uri": "https://localhost:8080/",
        "height": 35
       },
       "id": "j2XPde_ThM_e",
       "outputId": "a900c1b9-9a87-4078-968b-a5721deda5cb"
      },
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
        ]
       }
      ],
      "source": [
       "# Last 100 characters\n",
       "print(text_data[-99:])"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 19,
      "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
      "metadata": {
       "colab": {
        "base_uri": "https://localhost:8080/"
       },
       "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
       "outputId": "c2a25334-21ca-486e-8226-0296e5fc6486"
      },
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Characters: 20479\n",
         "Tokens: 5145\n"
        ]
       }
      ],
      "source": [
       "total_characters = len(text_data)\n",
       "total_tokens = len(tokenizer.encode(text_data))\n",
       "\n",
       "print(\"Characters:\", total_characters)\n",
       "print(\"Tokens:\", total_tokens)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "a8830cb9-90f6-4e7c-8620-beeabc2d39f7",
      "metadata": {},
      "source": [
       "- 5,145トークンしかないので、LLMの学習としては非常に小さいが、本書における教育用の例なので問題ないである\n",
       "- 本章の最後では事前学習済みの重みをロードする例も示す"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "bedcad87-a0e8-4b9d-ac43-4e927ccbb50f",
      "metadata": {},
      "source": [
       "- 次に、学習セットと検証セットに分割し、第2章で実装したデータローダを使って学習バッチを作成するである\n",
       "- 下図は`max_length=6`の例を示しており、実際に学習する際はLLMがサポートする`context_length`でバッチングされる\n",
       "- 図中では入力トークンのみを示しているが、LLMでは次のトークンを予測するため、学習時はターゲットはこれを1個シフトした形になる"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "46bdaa07-ba96-4ac1-9d71-b3cc153910d9",
      "metadata": {},
      "source": [
       "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/batching.webp\" width=500px>"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0959c855-f860-4358-8b98-bc654f047578",
      "metadata": {},
      "outputs": [],
      "source": [
       "from previous_chapters import create_dataloader_v1\n",
       "# Alternatively:\n",
       "# from llms_from_scratch.ch02 import create_dataloader_v1\n",
       "\n",
       "# Train/validation ratio\n",
       "train_ratio = 0.90\n",
       "split_idx = int(train_ratio * len(text_data))\n",
       "train_data = text_data[:split_idx]\n",
       "val_data = text_data[split_idx:]\n",
       "\n",
       "\n",
       "torch.manual_seed(123)\n",
       "\n",
       "train_loader = create_dataloader_v1(\n",
       "    train_data,\n",
       "    batch_size=2,\n",
       "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
       "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
       "    drop_last=True,\n",
       "    shuffle=True,\n",
       "    num_workers=0\n",
       ")\n",
       "\n",
       "val_loader = create_dataloader_v1(\n",
       "    val_data,\n",
       "    batch_size=2,\n",
       "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
       "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
       "    drop_last=False,\n",
       "    shuffle=False,\n",
       "    num_workers=0\n",
       ")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 21,
      "id": "f37b3eb0-854e-4895-9898-fa7d1e67566e",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Sanity check\n",
       "\n",
       "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
       "    print(\"Not enough tokens for the training loader. \"\n",
       "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
       "          \"increase the `training_ratio`\")\n",
       "\n",
       "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
       "    print(\"Not enough tokens for the validation loader. \"\n",
       "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
       "          \"decrease the `training_ratio`\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "e7ac3296-a4d1-4303-9ac5-376518960c33",
      "metadata": {},
      "source": [
       "- 学習用データセットが非常に小さいのでバッチサイズも小さめにしている（バッチサイズが2）\n",
       "- 参考として、Llama 2 7Bの学習時のバッチサイズは1024だったとされる"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "a8e0514d-b990-4dc0-9afb-7721993284a0",
      "metadata": {},
      "source": [
       "- オプションとして、データが正しく読み込まれているかの確認:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ca0116d0-d229-472c-9fbf-ebc229331c3e",
      "metadata": {},
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Train loader:\n",
         "torch.Size([2, 256]) torch.Size([2, 256])\n",
         "torch.Size([2, 256]) torch.Size([2, 256])\n",
         "torch.Size([2, 256]) torch.Size([2, 256])\n",
         "torch.Size([2, 256]) torch.Size([2, 256])\n",
         "torch.Size([2, 256]) torch.Size([2, 256])\n",
         "torch.Size([2, 256]) torch.Size([2, 256])\n",
         "torch.Size([2, 256]) torch.Size([2, 256])\n",
         "torch.Size([2, 256]) torch.Size([2, 256])\n",
         "torch.Size([2, 256]) torch.Size([2, 256])\n",
         "\n",
         "Validation loader:\n",
         "torch.Size([2, 256]) torch.Size([2, 256])\n"
        ]
       }
      ],
      "source": [
       "print(\"Train loader:\")\n",
       "for x, y in train_loader:\n",
       "    print(x.shape, y.shape)\n",
       "\n",
       "print(\"\\nValidation loader:\")\n",
       "for x, y in val_loader:\n",
       "    print(x.shape, y.shape)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "f7b9b1a4-863d-456f-a8dd-c07fb5c024ed",
      "metadata": {},
      "source": [
       "- さらにオプションとして、トークン数の整合性チェック:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 23,
      "id": "eb860488-5453-41d7-9870-23b723f742a0",
      "metadata": {
       "colab": {
        "base_uri": "https://localhost:8080/"
       },
       "id": "eb860488-5453-41d7-9870-23b723f742a0",
       "outputId": "96b9451a-9557-4126-d1c8-51610a1995ab"
      },
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Training tokens: 4608\n",
         "Validation tokens: 512\n",
         "All tokens: 5120\n"
        ]
       }
      ],
      "source": [
       "train_tokens = 0\n",
       "for input_batch, target_batch in train_loader:\n",
       "    train_tokens += input_batch.numel()\n",
       "\n",
       "val_tokens = 0\n",
       "for input_batch, target_batch in val_loader:\n",
       "    val_tokens += input_batch.numel()\n",
       "\n",
       "print(\"Training tokens:\", train_tokens)\n",
       "print(\"Validation tokens:\", val_tokens)\n",
       "print(\"All tokens:\", train_tokens + val_tokens)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "5c3085e8-665e-48eb-bb41-cdde61537e06",
      "metadata": {},
      "source": [
       "- 以上の準備ができたら、次のようにあるバッチのクロスエントロピー損失を計算するユーティリティ関数を定義するである\n",
       "- また、データローダ内の指定数のバッチに対してまとめてロスを計算する2つめのユーティリティ関数も定義する"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 24,
      "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc",
      "metadata": {
       "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc"
      },
      "outputs": [],
      "source": [
       "def calc_loss_batch(input_batch, target_batch, model, device):\n",
       "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
       "    logits = model(input_batch)\n",
       "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
       "    return loss\n",
       "\n",
       "\n",
       "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
       "    total_loss = 0.\n",
       "    if len(data_loader) == 0:\n",
       "        return float(\"nan\")\n",
       "    elif num_batches is None:\n",
       "        num_batches = len(data_loader)\n",
       "    else:\n",
       "        # Reduce the number of batches to match the total number of batches in the data loader\n",
       "        # if num_batches exceeds the number of batches in the data loader\n",
       "        num_batches = min(num_batches, len(data_loader))\n",
       "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
       "        if i < num_batches:\n",
       "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
       "            total_loss += loss.item()\n",
       "        else:\n",
       "            break\n",
       "    return total_loss / num_batches"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "f0691332-84d0-48b3-b462-a885ddeb4fca",
      "metadata": {},
      "source": [
       "- CUDA対応GPUを持つマシンであれば、特に変更を加えなくてもGPU上で学習を行える\n",
       "- `device`で指定したデバイスに、ミニバッチを載せるコードを書いているのもそのためである"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 25,
      "id": "56f5b0c9-1065-4d67-98b9-010e42fc1e2a",
      "metadata": {},
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Training loss: 10.98758347829183\n",
         "Validation loss: 10.98110580444336\n"
        ]
       }
      ],
      "source": [
       "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
       "\n",
       "# Note:\n",
       "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
       "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
       "# However, the resulting loss values may be slightly different.\n",
       "\n",
       "#if torch.cuda.is_available():\n",
       "#    device = torch.device(\"cuda\")\n",
       "#elif torch.backends.mps.is_available():\n",
       "#    device = torch.device(\"mps\")\n",
       "#else:\n",
       "#    device = torch.device(\"cpu\")\n",
       "#\n",
       "# print(f\"Using {device} device.\")\n",
       "\n",
       "\n",
       "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
       "\n",
       "\n",
       "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
       "\n",
       "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
       "    train_loss = calc_loss_loader(train_loader, model, device)\n",
       "    val_loss = calc_loss_loader(val_loader, model, device)\n",
       "\n",
       "print(\"Training loss:\", train_loss)\n",
       "print(\"Validation loss:\", val_loss)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "43875e95-190f-4b17-8f9a-35034ba649ec",
      "metadata": {},
      "source": [
       "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-1.webp\" width=400px>"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "b9339f8d-00cb-4206-af67-58c32bd72055",
      "metadata": {
       "id": "b9339f8d-00cb-4206-af67-58c32bd72055"
      },
      "source": [
       "## 5.2 LLMの学習"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "652a4cf4-e98f-46d9-bdec-60e7ccb8d6bd",
      "metadata": {},
      "source": [
       "- いよいよLLM学習のコードを示すである\n",
       "- ここではシンプルな学習関数を実装している（学習率ウォームアップ、コサインアニーリング、勾配クリッピングなどの高度なテクニックを組み込む例は[付録D](../../appendix-D/01_main-chapter-code)を参照）\n",
       "\n",
       "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/train-steps.webp\" width=300px>"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 26,
      "id": "Mtp4gY0ZO-qq",
      "metadata": {
       "id": "Mtp4gY0ZO-qq"
      },
      "outputs": [],
      "source": [
       "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
       "                       eval_freq, eval_iter, start_context, tokenizer):\n",
       "    # Initialize lists to track losses and tokens seen\n",
       "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
       "    tokens_seen, global_step = 0, -1\n",
       "\n",
       "    # Main training loop\n",
       "    for epoch in range(num_epochs):\n",
       "        model.train()  # Set model to training mode\n",
       "        \n",
       "        for input_batch, target_batch in train_loader:\n",
       "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
       "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
       "            loss.backward() # Calculate loss gradients\n",
       "            optimizer.step() # Update model weights using loss gradients\n",
       "            tokens_seen += input_batch.numel()\n",
       "            global_step += 1\n",
       "\n",
       "            # Optional evaluation step\n",
       "            if global_step % eval_freq == 0:\n",
       "                train_loss, val_loss = evaluate_model(\n",
       "                    model, train_loader, val_loader, device, eval_iter)\n",
       "                train_losses.append(train_loss)\n",
       "                val_losses.append(val_loss)\n",
       "                track_tokens_seen.append(tokens_seen)\n",
       "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
       "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
       "\n",
       "        # Print a sample text after each epoch\n",
       "        generate_and_print_sample(\n",
       "            model, tokenizer, device, start_context\n",
       "        )\n",
       "\n",
       "    return train_losses, val_losses, track_tokens_seen\n",
       "\n",
       "\n",
       "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
       "    model.eval()\n",
       "    with torch.no_grad():\n",
       "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
       "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
       "    model.train()\n",
       "    return train_loss, val_loss\n",
       "\n",
       "\n",
       "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
       "    model.eval()\n",
       "    context_size = model.pos_emb.weight.shape[0]\n",
       "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
       "    with torch.no_grad():\n",
       "        token_ids = generate_text_simple(\n",
       "            model=model, idx=encoded,\n",
       "            max_new_tokens=50, context_size=context_size\n",
       "        )\n",
       "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
       "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
       "    model.train()"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "a301b333-b9d4-4eeb-a212-3a9874e3ac47",
      "metadata": {},
      "source": [
       "- 上の学習関数を使い、以下のように実際にLLMを学習してみるである"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 27,
      "id": "3422000b-7aa2-485b-92df-99372cd22311",
      "metadata": {
       "colab": {
        "base_uri": "https://localhost:8080/"
       },
       "id": "3422000b-7aa2-485b-92df-99372cd22311",
       "outputId": "0e046603-908d-4093-8ae5-ef2f632639fb"
      },
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Ep 1 (Step 000000): Train loss 9.781, Val loss 9.933\n",
         "Ep 1 (Step 000005): Train loss 8.111, Val loss 8.339\n",
         "Every effort moves you,,,,,,,,,,,,.                                     \n",
         "Ep 2 (Step 000010): Train loss 6.661, Val loss 7.048\n",
         "Ep 2 (Step 000015): Train loss 5.961, Val loss 6.616\n",
         "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
         "Ep 3 (Step 000020): Train loss 5.726, Val loss 6.600\n",
         "Ep 3 (Step 000025): Train loss 5.201, Val loss 6.348\n",
         "Every effort moves you, and I had been.                                            \n",
         "Ep 4 (Step 000030): Train loss 4.417, Val loss 6.278\n",
         "Ep 4 (Step 000035): Train loss 4.069, Val loss 6.226\n",
         "Every effort moves you know the                          \"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
         "Ep 5 (Step 000040): Train loss 3.732, Val loss 6.160\n",
         "Every effort moves you know it was not that the picture--I had the fact by the last I had been--his, and in the            \"Oh, and he said, and down the room, and in\n",
         "Ep 6 (Step 000045): Train loss 2.850, Val loss 6.179\n",
         "Ep 6 (Step 000050): Train loss 2.427, Val loss 6.141\n",
         "Every effort moves you know,\" was one of the picture. The--I had a little of a little: \"Yes, and in fact, and in the picture was, and I had been at my elbow and as his pictures, and down the room, I had\n",
         "Ep 7 (Step 000055): Train loss 2.104, Val loss 6.134\n",
         "Ep 7 (Step 000060): Train loss 1.882, Val loss 6.233\n",
         "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no--as! The women had been, in the moment--as Jack himself, as once one had been the donkey, and were, and in his\n",
         "Ep 8 (Step 000065): Train loss 1.320, Val loss 6.238\n",
         "Ep 8 (Step 000070): Train loss 0.985, Val loss 6.242\n",
         "Every effort moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
         "Ep 9 (Step 000075): Train loss 0.717, Val loss 6.293\n",
         "Ep 9 (Step 000080): Train loss 0.541, Val loss 6.393\n",
         "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I had the donkey. \"There were days when I\n",
         "Ep 10 (Step 000085): Train loss 0.391, Val loss 6.452\n",
         "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n"
        ]
       }
      ],
      "source": [
       "# Note:\n",
       "# Uncomment the following code to calculate the execution time\n",
       "# import time\n",
       "# start_time = time.time()\n",
       "\n",
       "torch.manual_seed(123)\n",
       "model = GPTModel(GPT_CONFIG_124M)\n",
       "model.to(device)\n",
       "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
       "\n",
       "num_epochs = 10\n",
       "train_losses, val_losses, tokens_seen = train_model_simple(\n",
       "    model, train_loader, val_loader, optimizer, device,\n",
       "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
       "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
       ")\n",
       "\n",
       "# Note:\n",
       "# Uncomment the following code to show the execution time\n",
       "# end_time = time.time()\n",
       "# execution_time_minutes = (end_time - start_time) / 60\n",
       "# print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 5
   }
   