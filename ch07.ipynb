{
    "cells": [
      {
        "cell_type": "markdown",
        "id": "12e91914-5f51-43fa-b65b-625e73b4d17b",
        "metadata": {
          "id": "12e91914-5f51-43fa-b65b-625e73b4d17b"
        },
        "source": [
          "<table style=\"width:100%\">\n",
          "<tr>\n",
          "<td style=\"vertical-align:middle; text-align:left;\">\n",
          "<font size=\"2\">\n",
          "これは <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a>（<a href=\"https://sebastianraschka.com\">Sebastian Raschka</a>著）の補足コードである<br>\n",
          "<br>コードリポジトリ: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
          "</font>\n",
          "</td>\n",
          "<td style=\"vertical-align:middle; text-align:left;\">\n",
          "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp?1\" width=\"100px\"></a>\n",
          "</td>\n",
          "</tr>\n",
          "</table>"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "c2520ec3-722f-4f44-bdd1-885b13e7afbf",
        "metadata": {
          "id": "c2520ec3-722f-4f44-bdd1-885b13e7afbf"
        },
        "source": [
          "# 第7章: 命令に従うファインチューニング"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 1,
        "id": "4e19327b-6c02-4881-ad02-9b6d3ec0b1b4",
        "metadata": {
          "colab": {
            "base_uri": "https://localhost:8080/"
          },
          "id": "4e19327b-6c02-4881-ad02-9b6d3ec0b1b4",
          "outputId": "bcdfe2cb-d084-4920-d703-503131aabec3"
        },
        "outputs": [
          {
            "name": "stdout",
            "output_type": "stream",
            "text": [
              "numpy version: 2.0.2\n",
              "matplotlib version: 3.10.0\n",
              "tiktoken version: 0.8.0\n",
              "torch version: 2.5.1+cu124\n",
              "tqdm version: 4.67.1\n",
              "tensorflow version: 2.18.0\n"
            ]
          }
        ],
        "source": [
          "from importlib.metadata import version\n",
          "\n",
          "pkgs = [\n",
          "    \"numpy\",       # PyTorch & TensorFlow dependency\n",
          "    \"matplotlib\",  # Plotting library\n",
          "    \"tiktoken\",    # Tokenizer\n",
          "    \"torch\",       # Deep learning library\n",
          "    \"tqdm\",        # Progress bar\n",
          "    \"tensorflow\",  # For OpenAI's pretrained weights\n",
          "]\n",
          "for p in pkgs:\n",
          "    print(f\"{p} version: {version(p)}\")"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "264fca98-2f9a-4193-b435-2abfa3b4142f",
        "metadata": {
          "id": "264fca98-2f9a-4193-b435-2abfa3b4142f"
        },
        "source": [
          "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/overview.webp?1\" width=500px>"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "8bbc68e9-75b3-41f1-ac2c-e071c3cd0813",
        "metadata": {
          "id": "8bbc68e9-75b3-41f1-ac2c-e071c3cd0813"
        },
        "source": [
          "## 7.1 インストラクションファインチューニングの導入"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "53dba24a-6805-496c-9a7f-c75e2d3527ab",
        "metadata": {
          "id": "53dba24a-6805-496c-9a7f-c75e2d3527ab"
        },
        "source": [
          "- 第5章で、LLMの事前学習では単語を1つずつ生成する手順を通じて学習することを見た\n",
          "- したがって、事前学習済みのLLMはテキストの補完に優れているが、命令に従うのは得意ではない\n",
          "- この章では、LLMが命令によりうまく従えるように学習する"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "18dc0535-0904-44ed-beaf-9b678292ef35",
        "metadata": {
          "id": "18dc0535-0904-44ed-beaf-9b678292ef35"
        },
        "source": [
          "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/instruction-following.webp\" width=500px>"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "b4698b23-12e0-4bd7-a140-ccb3dd71d4e8",
        "metadata": {
          "id": "b4698b23-12e0-4bd7-a140-ccb3dd71d4e8"
        },
        "source": [
          "- この章の内容は下図のようにまとめられる\n",
          "\n",
          "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-1.webp?1\" width=500px>"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "5384f0cf-ef3c-4436-a5fa-59bd25649f86",
        "metadata": {
          "id": "5384f0cf-ef3c-4436-a5fa-59bd25649f86"
        },
        "source": [
          "## 7.2 スーパーバイザードなインストラクションファインチューニング用データセットの準備"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "f8b34ff8-619f-4e89-bd03-ce513269760d",
        "metadata": {
          "id": "f8b34ff8-619f-4e89-bd03-ce513269760d"
        },
        "source": [
          "- この章で使用するインストラクション用データセットを用意してある"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 2,
        "id": "0G3axLw6kY1N",
        "metadata": {
          "colab": {
            "base_uri": "https://localhost:8080/"
          },
          "id": "0G3axLw6kY1N",
          "outputId": "07e1e4f9-026c-48c1-8a06-f2bfb1fb354e"
        },
        "outputs": [
          {
            "name": "stdout",
            "output_type": "stream",
            "text": [
              "Number of entries: 1100\n"
            ]
          }
        ],
        "source": [
          "import json\n",
          "import os\n",
          "import urllib\n",
          "\n",
          "\n",
          "def download_and_load_file(file_path, url):\n",
          "\n",
          "    if not os.path.exists(file_path):\n",
          "        with urllib.request.urlopen(url) as response:\n",
          "            text_data = response.read().decode(\"utf-8\")\n",
          "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
          "            file.write(text_data)\n",
          "\n",
          "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
          "        data = json.load(file)\n",
          "\n",
          "    return data\n",
          "\n",
          "file_path = \"instruction-data.json\"\n",
          "url = (\n",
          "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
          "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
          ")\n",
          "\n",
          "data = download_and_load_file(file_path, url)\n",
          "print(\"Number of entries:\", len(data))"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "d7af8176-4255-4e92-8c7d-998771733eb8",
        "metadata": {
          "id": "d7af8176-4255-4e92-8c7d-998771733eb8"
        },
        "source": [
          "- 上で読み込んだ `data` リストの各要素は、次の形式をとる辞書である"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 3,
        "id": "-LiuBMsHkzQV",
        "metadata": {
          "colab": {
            "base_uri": "https://localhost:8080/"
          },
          "id": "-LiuBMsHkzQV",
          "outputId": "a4ee5c2d-db53-4a80-e5ee-0bbcf6fe0450"
        },
        "outputs": [
          {
            "name": "stdout",
            "output_type": "stream",
            "text": [
              "Example entry:\n",
              " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
            ]
          }
        ],
        "source": [
          "print(\"Example entry:\\n\", data[50])"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "c5a32b34-485a-4816-a77a-da14f9fe6e46",
        "metadata": {
          "id": "c5a32b34-485a-4816-a77a-da14f9fe6e46"
        },
        "source": [
          "- `'input'` フィールドは空である場合がある:"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 4,
        "id": "uFInFxDDk2Je",
        "metadata": {
          "colab": {
            "base_uri": "https://localhost:8080/"
          },
          "id": "uFInFxDDk2Je",
          "outputId": "b4f84027-bb9e-4e51-b79e-1329c8bff093"
        },
        "outputs": [
          {
            "name": "stdout",
            "output_type": "stream",
            "text": [
              "Another example entry:\n",
              " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
            ]
          }
        ],
        "source": [
          "print(\"Another example entry:\\n\", data[999])"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "f034799a-6575-45fd-98c9-9d1012d0fd58",
        "metadata": {
          "id": "f034799a-6575-45fd-98c9-9d1012d0fd58"
        },
        "source": [
          "- インストラクションファインチューニングは、しばしば「スーパーバイザードインストラクションファインチューニング」と呼ばれる。これは、入力と出力のペアが明示的に与えられたデータセットを用いてモデルを訓練するためである\n",
          "- エントリをLLMへの入力として整形する方法はいくつかある。下図は、Alpaca (https://crfm.stanford.edu/2023/03/13/alpaca.html) と Phi-3 (https://arxiv.org/abs/2404.14219) というLLMの訓練に用いられた2つの例示的なフォーマットである"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "dffa4f70-44d4-4be4-89a9-2159f4885b10",
        "metadata": {
          "id": "dffa4f70-44d4-4be4-89a9-2159f4885b10"
        },
        "source": [
          "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/prompt-style.webp?1\" width=500px>"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "dd79a74e-befb-491c-be49-f777a6a5b6a6",
        "metadata": {
          "id": "dd79a74e-befb-491c-be49-f777a6a5b6a6"
        },
        "source": [
          "- この章では、Alpacaスタイルのプロンプトフォーマットを使用する。これは元々インストラクションファインチューニングに用いられていたプロンプトテンプレートである\n",
          "- 以下では、LLMに入力として渡すためのテキストを整形している"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 5,
        "id": "Jhk37nnJnkBh",
        "metadata": {
          "id": "Jhk37nnJnkBh"
        },
        "outputs": [],
        "source": [
          "def format_input(entry):\n",
          "    instruction_text = (\n",
          "        f\"Below is an instruction that describes a task. \"\n",
          "        f\"Write a response that appropriately completes the request.\"\n",
          "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
          "    )\n",
          "\n",
          "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
          "\n",
          "    return instruction_text + input_text"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "011e78b4-e89a-4653-a2ee-7b2739ca04d6",
        "metadata": {
          "id": "011e78b4-e89a-4653-a2ee-7b2739ca04d6"
        },
        "source": [
          "- `input` フィールドがある場合の整形例は以下である"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 6,
        "id": "F9UQRfjzo4Js",
        "metadata": {
          "colab": {
            "base_uri": "https://localhost:8080/"
          },
          "id": "F9UQRfjzo4Js",
          "outputId": "7b615d35-2a5f-474d-9292-a69bc3850e16"
        },
        "outputs": [
          {
            "name": "stdout",
            "output_type": "stream",
            "text": [
              "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
              "\n",
              "### Instruction:\n",
              "Identify the correct spelling of the following word.\n",
              "\n",
              "### Input:\n",
              "Ocassion\n",
              "\n",
              "### Response:\n",
              "The correct spelling is 'Occasion.'\n"
            ]
          }
        ],
        "source": [
          "model_input = format_input(data[50])\n",
          "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
          "\n",
          "print(model_input + desired_response)"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "4dc93ddf-431c-49c0-96f2-fb3a79c4d94c",
        "metadata": {
          "id": "4dc93ddf-431c-49c0-96f2-fb3a79c4d94c"
        },
        "source": [
          "- `input` フィールドがない場合の整形例は以下である"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 7,
        "id": "a3891fa9-f738-41cd-946c-80ef9a99c346",
        "metadata": {
          "colab": {
            "base_uri": "https://localhost:8080/"
          },
          "id": "a3891fa9-f738-41cd-946c-80ef9a99c346",
          "outputId": "2142c5a4-b594-49c5-affe-2d963a7bd46b"
        },
        "outputs": [
          {
            "name": "stdout",
            "output_type": "stream",
            "text": [
              "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
              "\n",
              "### Instruction:\n",
              "What is an antonym of 'complicated'?\n",
              "\n",
              "### Response:\n",
              "An antonym of 'complicated' is 'simple'.\n"
            ]
          }
        ],
        "source": [
          "model_input = format_input(data[999])\n",
          "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
          "\n",
          "print(model_input + desired_response)"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "4aa8afd5-2a21-49a5-90c3-6a03865a4771",
        "metadata": {
          "id": "4aa8afd5-2a21-49a5-90c3-6a03865a4771"
        },
        "source": [
          "- 最後に、次のセクションでPyTorchのデータローダーを用意する前に、データセットを訓練・バリデーション・テストの3つに分割する"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 8,
        "id": "aFZVopbIlNfx",
        "metadata": {
          "id": "aFZVopbIlNfx"
        },
        "outputs": [],
        "source": [
          "train_portion = int(len(data) * 0.85)  # 85% for training\n",
          "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
          "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
          "\n",
          "train_data = data[:train_portion]\n",
          "test_data = data[train_portion:train_portion + test_portion]\n",
          "val_data = data[train_portion + test_portion:]"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 9,
        "id": "-zf6oht6bIUQ",
        "metadata": {
          "colab": {
            "base_uri": "https://localhost:8080/"
          },
          "id": "-zf6oht6bIUQ",
          "outputId": "657ec5c6-4caa-4d1a-ba2e-23acd755ab07"
        },
        "outputs": [
          {
            "name": "stdout",
            "output_type": "stream",
            "text": [
              "Training set length: 935\n",
              "Validation set length: 55\n",
              "Test set length: 110\n"
            ]
          }
        ],
        "source": [
          "print(\"Training set length:\", len(train_data))\n",
          "print(\"Validation set length:\", len(val_data))\n",
          "print(\"Test set length:\", len(test_data))"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "fcaaf606-f913-4445-8301-632ae10d387d",
        "metadata": {
          "id": "fcaaf606-f913-4445-8301-632ae10d387d"
        },
        "source": [
          "## 7.3 訓練バッチへのデータ整理"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "233f63bd-9755-4d07-8884-5e2e5345cf27",
        "metadata": {
          "id": "233f63bd-9755-4d07-8884-5e2e5345cf27"
        },
        "source": [
          "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-2.webp?1\" width=500px>"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "c149fc1a-7757-4ec8-80cb-e2a3fb007a2c",
        "metadata": {
          "id": "c149fc1a-7757-4ec8-80cb-e2a3fb007a2c"
        },
        "source": [
          "- このデータセットのバッチングは、下図にまとめたように複数のステップで行う\n",
          "\n",
          "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/detailed-batching.webp?1\" width=500px>"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "b9af423f-aad9-4b3c-bea5-153021c04862",
        "metadata": {
          "id": "b9af423f-aad9-4b3c-bea5-153021c04862"
        },
        "source": [
          "- まず、第6章の `SpamDataset` と同様に、データセット内の入力をあらかじめトークナイズする `InstructionDataset` クラスを実装する\n",
          "\n",
          "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/pretokenizing.webp\" width=500px>"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 10,
        "id": "adc29dc4-f1c7-4c71-937b-95119d6239bb",
        "metadata": {
          "id": "adc29dc4-f1c7-4c71-937b-95119d6239bb"
        },
        "outputs": [],
        "source": [
          "import torch\n",
          "from torch.utils.data import Dataset\n",
          "\n",
          "\n",
          "class InstructionDataset(Dataset):\n",
          "    def __init__(self, data, tokenizer):\n",
          "        self.data = data\n",
          "\n",
          "        # Pre-tokenize texts\n",
          "        self.encoded_texts = []\n",
          "        for entry in data:\n",
          "            instruction_plus_input = format_input(entry)\n",
          "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
          "            full_text = instruction_plus_input + response_text\n",
          "            self.encoded_texts.append(\n",
          "                tokenizer.encode(full_text)\n",
          "            )\n",
          "\n",
          "    def __getitem__(self, index):\n",
          "        return self.encoded_texts[index]\n",
          "\n",
          "    def __len__(self):\n",
          "        return len(self.data)"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "384f0e69-4b22-41c0-a25d-f077527eddd1",
        "metadata": {
          "id": "384f0e69-4b22-41c0-a25d-f077527eddd1"
        },
        "source": [
          "- 第6章と同様に、訓練を加速するために複数のサンプルをバッチ化する必要がある。このとき、入力の長さを揃えるためにパディングが必要になる\n",
          "- 前章と同様に、パディングトークンとして `<|endoftext|>` （ID 50256）を使う"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 11,
        "id": "ff24fe1a-5746-461c-ad3d-b6d84a1a7c96",
        "metadata": {
          "colab": {
            "base_uri": "https://localhost:8080/"
          },
          "id": "ff24fe1a-5746-461c-ad3d-b6d84a1a7c96",
          "outputId": "ac44227b-9ec2-4131-9df8-89caa6e879ca"
        },
        "outputs": [
          {
            "name": "stdout",
            "output_type": "stream",
            "text": [
              "[50256]\n"
            ]
          }
        ],
        "source": [
          "import tiktoken\n",
          "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
          "\n",
          "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "9e5bd7bc-f347-4cf8-a0c2-94cb8799e427",
        "metadata": {
          "id": "9e5bd7bc-f347-4cf8-a0c2-94cb8799e427"
        },
        "source": [
          "- 第6章では、データセット内のすべてのサンプルを同じ長さにパディングした\n",
          "  - 今回は、バッチごとに異なる最大長に合わせてパディングを行うためのカスタム`collate`関数を作成する\n",
          "  - これにより、各バッチ内のみ同じ長さにそろえる（バッチ間では長さが違う可能性がある）"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "65c4d943-4aa8-4a44-874e-05bc6831fbd3",
        "metadata": {
          "id": "65c4d943-4aa8-4a44-874e-05bc6831fbd3"
        },
        "source": [
          "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/padding.webp\" width=500px>"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 12,
        "id": "eb4c77dd-c956-4a1b-897b-b466909f18ca",
        "metadata": {
          "id": "eb4c77dd-c956-4a1b-897b-b466909f18ca"
        },
        "outputs": [],
        "source": [
          "def custom_collate_draft_1(\n",
          "    batch,\n",
          "    pad_token_id=50256,\n",
          "    device=\"cpu\"\n",
          "):\n",
          "    # Find the longest sequence in the batch\n",
          "    # and increase the max length by +1, which will add one extra\n",
          "    # padding token below\n",
          "    batch_max_length = max(len(item)+1 for item in batch)\n",
          "\n",
          "    # Pad and prepare inputs\n",
          "    inputs_lst = []\n",
          "\n",
          "    for item in batch:\n",
          "        new_item = item.copy()\n",
          "        # Add an <|endoftext|> token\n",
          "        new_item += [pad_token_id]\n",
          "        # Pad sequences to batch_max_length\n",
          "        padded = (\n",
          "            new_item + [pad_token_id] *\n",
          "            (batch_max_length - len(new_item))\n",
          "        )\n",
          "        # Via padded[:-1], we remove the extra padded token\n",
          "        # that has been added via the +1 setting in batch_max_length\n",
          "        # (the extra padding token will be relevant in later codes)\n",
          "        inputs = torch.tensor(padded[:-1])\n",
          "        inputs_lst.append(inputs)\n",
          "\n",
          "    # Convert list of inputs to tensor and transfer to target device\n",
          "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
          "    return inputs_tensor"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 13,
        "id": "8fb02373-59b3-4f3a-b1d1-8181a2432645",
        "metadata": {
          "colab": {
            "base_uri": "https://localhost:8080/"
          },
          "id": "8fb02373-59b3-4f3a-b1d1-8181a2432645",
          "outputId": "93d987b9-e3ca-4857-9b28-b67d515a94d8"
        },
        "outputs": [
          {
            "name": "stdout",
            "output_type": "stream",
            "text": [
              "tensor([[    0,     1,     2,     3,     4],\n",
              "        [    5,     6, 50256, 50256, 50256],\n",
              "        [    7,     8,     9, 50256, 50256]])\n"
            ]
          }
        ],
        "source": [
          "inputs_1 = [0, 1, 2, 3, 4]\n",
          "inputs_2 = [5, 6]\n",
          "inputs_3 = [7, 8, 9]\n",
          "\n",
          "batch = (\n",
          "    inputs_1,\n",
          "    inputs_2,\n",
          "    inputs_3\n",
          ")\n",
          "\n",
          "print(custom_collate_draft_1(batch))"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "c46832ab-39b7-45f8-b330-ac9adfa10d1b",
        "metadata": {
          "id": "c46832ab-39b7-45f8-b330-ac9adfa10d1b"
        },
        "source": [
          "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/batching-step-4.webp?1\" width=500px>"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "17769a19-b961-4213-92ef-34f441b2d1d6",
        "metadata": {
          "id": "17769a19-b961-4213-92ef-34f441b2d1d6"
        },
        "source": [
          "- 上の例ではLLMへの入力のみ返している。しかしLLMの学習にはターゲット値も必要である\n",
          "- 事前学習と同様、ターゲットは1つ右にシフトされた入力であり、次のトークンを予測するように学習する"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "0386b6fe-3455-4e70-becd-a5a4681ba2ef",
        "metadata": {
          "id": "0386b6fe-3455-4e70-becd-a5a4681ba2ef"
        },
        "source": [
          "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/inputs-targets.webp?1\" width=400px>"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 14,
        "id": "74af192e-757c-4c0a-bdf9-b7eb25bf6ebc",
        "metadata": {
          "id": "74af192e-757c-4c0a-bdf9-b7eb25bf6ebc"
        },
        "outputs": [],
        "source": [
          "def custom_collate_draft_2(\n",
          "    batch,\n",
          "    pad_token_id=50256,\n",
          "    device=\"cpu\"\n",
          "):\n",
          "    # Find the longest sequence in the batch\n",
          "    batch_max_length = max(len(item)+1 for item in batch)\n",
          "\n",
          "    # Pad and prepare inputs\n",
          "    inputs_lst, targets_lst = [], []\n",
          "\n",
          "    for item in batch:\n",
          "        new_item = item.copy()\n",
          "        # Add an <|endoftext|> token\n",
          "        new_item += [pad_token_id]\n",
          "        # Pad sequences to max_length\n",
          "        padded = (\n",
          "            new_item + [pad_token_id] *\n",
          "            (batch_max_length - len(new_item))\n",
          "        )\n",
          "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
          "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
          "        inputs_lst.append(inputs)\n",
          "        targets_lst.append(targets)\n",
          "\n",
          "    # Convert list of inputs to tensor and transfer to target device\n",
          "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
          "    targets_tensor = torch.stack(targets_lst).to(device)\n",
          "    return inputs_tensor, targets_tensor"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 15,
        "id": "6eb2bce3-28a7-4f39-9d4b-5e972d69066c",
        "metadata": {
          "colab": {
            "base_uri": "https://localhost:8080/"
          },
          "id": "6eb2bce3-28a7-4f39-9d4b-5e972d69066c",
          "outputId": "3d104439-c328-431b-ef7c-2639d86c2135"
        },
        "outputs": [
          {
            "name": "stdout",
            "output_type": "stream",
            "text": [
              "tensor([[    0,     1,     2,     3,     4],\n",
              "        [    5,     6, 50256, 50256, 50256],\n",
              "        [    7,     8,     9, 50256, 50256]])\n",
              "tensor([[    1,     2,     3,     4, 50256],\n",
              "        [    6, 50256, 50256, 50256, 50256],\n",
              "        [    8,     9, 50256, 50256, 50256]])\n"
            ]
          }
        ],
        "source": [
          "inputs, targets = custom_collate_draft_2(batch)\n",
          "print(inputs)\n",
          "print(targets)"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "3bf85703-a0e0-42aa-8f29-cbc28dbf4e15",
        "metadata": {
          "id": "3bf85703-a0e0-42aa-8f29-cbc28dbf4e15"
        },
        "source": [
          "- 次に `ignore_index` を導入して、パディングトークンIDを別の値に置き換える。この `ignore_index` の目的は、損失関数でパディング値を無視できるようにするためである\n",
          "\n",
          "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/batching-step-5.webp?1\" width=500px>\n",
          "\n",
          "- 具体的には、トークンID 50256 を -100 に置き換える（以下の図を参照）"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "bd4bed33-956e-4b3f-a09c-586d8203109a",
        "metadata": {
          "id": "bd4bed33-956e-4b3f-a09c-586d8203109a"
        },
        "source": [
          "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/ignore-index.webp?1\" width=500px>"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "5346513e-c3f4-44fe-af22-4ebd36497728",
        "metadata": {
          "id": "5346513e-c3f4-44fe-af22-4ebd36497728"
        },
        "source": [
          "- （さらに、GPT-2がサポートするコンテキストサイズ1024トークンを超えるような長いデータを使う場合に備え、`allowed_max_length` も導入している）"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 16,
        "id": "41ec6e2d-9eb2-4124-913e-d2af39be4cf2",
        "metadata": {
          "id": "41ec6e2d-9eb2-4124-913e-d2af39be4cf2"
        },
        "outputs": [],
        "source": [
          "def custom_collate_fn(\n",
          "    batch,\n",
          "    pad_token_id=50256,\n",
          "    ignore_index=-100,\n",
          "    allowed_max_length=None,\n",
          "    device=\"cpu\"\n",
          "):\n",
          "    # Find the longest sequence in the batch\n",
          "    batch_max_length = max(len(item)+1 for item in batch)\n",
          "\n",
          "    # Pad and prepare inputs and targets\n",
          "    inputs_lst, targets_lst = [], []\n",
          "\n",
          "    for item in batch:\n",
          "        new_item = item.copy()\n",
          "        # Add an <|endoftext|> token\n",
          "        new_item += [pad_token_id]\n",
          "        # Pad sequences to max_length\n",
          "        padded = (\n",
          "            new_item + [pad_token_id] *\n",
          "            (batch_max_length - len(new_item))\n",
          "        )\n",
          "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
          "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
          "\n",
          "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
          "        mask = targets == pad_token_id\n",
          "        indices = torch.nonzero(mask).squeeze()\n",
          "        if indices.numel() > 1:\n",
          "            targets[indices[1:]] = ignore_index\n",
          "\n",
          "        # New: Optionally truncate to maximum sequence length\n",
          "        if allowed_max_length is not None:\n",
          "            inputs = inputs[:allowed_max_length]\n",
          "            targets = targets[:allowed_max_length]\n",
          "\n",
          "        inputs_lst.append(inputs)\n",
          "        targets_lst.append(targets)\n",
          "\n",
          "    # Convert list of inputs and targets to tensors and transfer to target device\n",
          "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
          "    targets_tensor = torch.stack(targets_lst).to(device)\n",
          "\n",
          "    return inputs_tensor, targets_tensor"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 17,
        "id": "cdf5eec4-9ebe-4be0-9fca-9a47bee88fdc",
        "metadata": {
          "colab": {
            "base_uri": "https://localhost:8080/"
          },
          "id": "cdf5eec4-9ebe-4be0-9fca-9a47bee88fdc",
          "outputId": "e8f709b9-f4c5-428a-a6ac-2a4c1b9358ba"
        },
        "outputs": [
          {
            "name": "stdout",
            "output_type": "stream",
            "text": [
              "tensor([[    0,     1,     2,     3,     4],\n",
              "        [    5,     6, 50256, 50256, 50256],\n",
              "        [    7,     8,     9, 50256, 50256]])\n",
              "tensor([[    1,     2,     3,     4, 50256],\n",
              "        [    6, 50256,  -100,  -100,  -100],\n",
              "        [    8,     9, 50256,  -100,  -100]])\n"
            ]
          }
        ],
        "source": [
          "inputs, targets = custom_collate_fn(batch)\n",
          "print(inputs)\n",
          "print(targets)"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "26727c90-0d42-43b3-af21-0a66ad4fbbc7",
        "metadata": {
          "id": "26727c90-0d42-43b3-af21-0a66ad4fbbc7"
        },
        "source": [
          "- -100 に置き換えることでどうなるのかを見てみる\n",
          "- ここでは分かりやすいように、2クラス分類（0と1）のタスクを想定する（第6章で扱ったような単純な例）\n",
          "- 以下のようなロジット（モデルの最終出力）を考えた場合、損失は次のように計算される"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 18,
        "id": "W2jvh-OP9MFV",
        "metadata": {
          "colab": {
            "base_uri": "https://localhost:8080/"
          },
          "id": "W2jvh-OP9MFV",
          "outputId": "ccb3a703-59a7-4258-8841-57959a016e31"
        },
        "outputs": [
          {
            "name": "stdout",
            "output_type": "stream",
            "text": [
              "tensor(1.1269)\n"
            ]
          }
        ],
        "source": [
          "logits_1 = torch.tensor(\n",
          "    [[-1.0, 1.0],  # 1st training example\n",
          "     [-0.5, 1.5]]  # 2nd training example\n",
          ")\n",
          "targets_1 = torch.tensor([0, 1])\n",
          "\n",
          "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
          "print(loss_1)"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "5edd3244-8886-4505-92e9-367d28529e1e",
        "metadata": {
          "id": "5edd3244-8886-4505-92e9-367d28529e1e"
        },
        "source": [
          "- もう1つサンプルを追加すると、損失値は当然変化する"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 19,
        "id": "nvVMuil89v9N",
        "metadata": {
          "colab": {
            "base_uri": "https://localhost:8080/"
          },
          "id": "nvVMuil89v9N",
          "outputId": "6d4683d4-5bfc-4a8c-de2a-95ecb2e716b9"
        },
        "outputs": [
          {
            "name": "stdout",
            "output_type": "stream",
            "text": [
              "tensor(0.7936)\n"
            ]
          }
        ],
        "source": [
          "logits_2 = torch.tensor(\n",
          "    [[-1.0, 1.0],\n",
          "     [-0.5, 1.5],\n",
          "     [-0.5, 1.5]]  # New 3rd training example\n",
          ")\n",
          "targets_2 = torch.tensor([0, 1, 1])\n",
          "\n",
          "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
          "print(loss_2)"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "54dca331-40e0-468b-b690-189fe156ba8f",
        "metadata": {
          "id": "54dca331-40e0-468b-b690-189fe156ba8f"
        },
        "source": [
          "- このうち1つのサンプルのクラスラベルを-100に置き換えたらどうなるかを見てみる"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 20,
        "id": "RTyB1vah9p56",
        "metadata": {
          "colab": {
            "base_uri": "https://localhost:8080/"
          },
          "id": "RTyB1vah9p56",
          "outputId": "da05302e-3fe0-439e-d1ed-82066bceb122"
        },
        "outputs": [
          {
            "name": "stdout",
            "output_type": "stream",
            "text": [
              "tensor(1.1269)\n",
              "loss_1 == loss_3: tensor(True)\n"
            ]
          }
        ],
        "source": [
          "targets_3 = torch.tensor([0, 1, -100])\n",
          "\n",
          "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
          "print(loss_3)\n",
          "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "cef09d21-b652-4760-abea-4f76920e6a25",
        "metadata": {
          "id": "cef09d21-b652-4760-abea-4f76920e6a25"
        },
        "source": [
          "- 3つの訓練サンプルを使ったときの損失が、最初の2つのサンプルだけで計算した損失と同じになっている。つまり-100となっている例は無視されていることがわかる\n",
          "- PyTorchの `cross_entropy(..., ignore_index=-100)` は、ラベルが-100の例を無視するようにデフォルトで設定されている\n",
          "- -100の `ignore_index` を使うことで、追加で挿入したend-of-text（パディング）トークンを無視できる。一方、最初のend-of-text（パディング）トークンはLLMにとって応答の終了を示すために役立つので無視しない\n"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "6a4e9c5f-7c49-4321-9f1b-a50468a84524",
        "metadata": {
          "id": "6a4e9c5f-7c49-4321-9f1b-a50468a84524"
        },
        "source": [
          "- 実際には、命令部分に対応するターゲットトークンIDを無視することも一般的である（詳細は本章の演習として推奨）"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "fab8f0ed-80e8-4fd9-bf84-e5d0e0bc0a39",
        "metadata": {
          "id": "fab8f0ed-80e8-4fd9-bf84-e5d0e0bc0a39"
        },
        "source": [
          "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/mask-instructions.webp?1\" width=600px>"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "bccaf048-ec95-498c-9155-d5b3ccba6c96",
        "metadata": {
          "id": "bccaf048-ec95-498c-9155-d5b3ccba6c96"
        },
        "source": [
          "## 7.4 インストラクション用データセットに対するデータローダーの作成"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "e6b8e656-3af3-4db6-8dde-d8c216a12f50",
        "metadata": {
          "id": "e6b8e656-3af3-4db6-8dde-d8c216a12f50"
        },
        "source": [
          "- このセクションでは、`InstructionDataset` クラスと `custom_collate_fn` 関数を使って、訓練・バリデーション・テストデータのローダーを生成する"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "9fffe390-b226-4d5c-983f-9f4da773cb82",
        "metadata": {
          "id": "9fffe390-b226-4d5c-983f-9f4da773cb82"
        },
        "source": [
          "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-3.webp?1\" width=500px>"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "932677e9-9317-42e8-b461-7b0269518f97",
        "metadata": {
          "id": "932677e9-9317-42e8-b461-7b0269518f97"
        },
        "source": [
          "- 先ほどの `custom_collate_fn` では、バッチ単位でデバイス（GPUなど）にデータを移動している。これにより、トレーニングループで都度データを移動するよりも効率がよくなる（バックグラウンド処理として行われるため）。\n",
          "- Pythonの標準ライブラリ `functools` の `partial` を使うことで、`device` 引数をあらかじめ指定した関数を生成できる"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 21,
        "id": "etpqqWh8phKc",
        "metadata": {
          "colab": {
            "base_uri": "https://localhost:8080/"
          },
          "id": "etpqqWh8phKc",
          "outputId": "b4391c33-1a89-455b-faaa-5f874b6eb409"
        },
        "outputs": [
          {
            "name": "stdout",
            "output_type": "stream",
            "text": [
              "Device: cuda\n"
            ]
          }
        ],
        "source": [
          "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
          "\n",
          "# Note:\n",
          "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
          "# which is much faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
          "# However, the resulting loss values may be slightly different.\n",
          "\n",
          "#if torch.cuda.is_available():\n",
          "#    device = torch.device(\"cuda\")\n",
          "#elif torch.backends.mps.is_available():\n",
          "#    device = torch.device(\"mps\")\n",
          "#else:\n",
          "#    device = torch.device(\"cpu\")\n",
          "\n",
          "print(\"Device:\", device)"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 22,
        "id": "4e47fb30-c2c6-4e6d-a64c-76cc65be4a2c",
        "metadata": {
          "id": "4e47fb30-c2c6-4e6d-a64c-76cc65be4a2c"
        },
        "outputs": [],
        "source": [
          "from functools import partial\n",
          "\n",
          "customized_collate_fn = partial(\n",
          "    custom_collate_fn,\n",
          "    device=device,\n",
          "    allowed_max_length=1024\n",
          ")"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "8ff42c29-8b81-45e5-ae8d-b97cd1cf447a",
        "metadata": {
          "id": "8ff42c29-8b81-45e5-ae8d-b97cd1cf447a"
        },
        "source": [
          "- 次に、これまでの章と同様の手順でデータローダーを生成する。ただし今回はバッチングの際に先ほどの `custom_collate_fn` を指定している"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 23,
        "id": "BtWkgir6Hlpe",
        "metadata": {
          "id": "BtWkgir6Hlpe"
        },
        "outputs": [],
        "source": [
          "from torch.utils.data import DataLoader\n",
          "\n",
          "\n",
          "num_workers = 0\n",
          "batch_size = 8\n",
          "\n",
          "torch.manual_seed(123)\n",
          "\n",
          "train_dataset = InstructionDataset(train_data, tokenizer)\n",
          "train_loader = DataLoader(\n",
          "    train_dataset,\n",
          "    batch_size=batch_size,\n",
          "    collate_fn=customized_collate_fn,\n",
          "    shuffle=True,\n",
          "    drop_last=True,\n",
          "    num_workers=num_workers\n",
          ")"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 24,
        "id": "1d097dc8-ad34-4f05-b435-e4147965f532",
        "metadata": {
          "id": "1d097dc8-ad34-4f05-b435-e4147965f532"
        },
        "outputs": [],
        "source": [
          "val_dataset = InstructionDataset(val_data, tokenizer)\n",
          "val_loader = DataLoader(\n",
          "    val_dataset,\n",
          "    batch_size=batch_size,\n",
          "    collate_fn=customized_collate_fn,\n",
          "    shuffle=False,\n",
          "    drop_last=False,\n",
          "    num_workers=num_workers\n",
          ")\n",
          "\n",
          "test_dataset = InstructionDataset(test_data, tokenizer)\n",
          "test_loader = DataLoader(\n",
          "    test_dataset,\n",
          "    batch_size=batch_size,\n",
          "    collate_fn=customized_collate_fn,\n",
          "    shuffle=False,\n",
          "    drop_last=False,\n",
          "    num_workers=num_workers\n",
          ")"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "3f67c147-b1a2-4a95-9807-e2d0de0324c0",
        "metadata": {
          "id": "3f67c147-b1a2-4a95-9807-e2d0de0324c0"
        },
        "source": [
          "- 生成される入力バッチとターゲットバッチの次元を確認する"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 25,
        "id": "GGs1AI3vHpnX",
        "metadata": {
          "colab": {
            "base_uri": "https://localhost:8080/"
          },
          "id": "GGs1AI3vHpnX",
          "outputId": "f6a74c8b-1af3-4bc1-b48c-eda64b0200d1"
        },
        "outputs": [
          {
            "name": "stdout",
            "output_type": "stream",
            "text": [
              "Train loader:\n",
              "torch.Size([8, 61]) torch.Size([8, 61])\n",
              "torch.Size([8, 76]) torch.Size([8, 76])\n",
              "torch.Size([8, 73]) torch.Size([8, 73])\n",
              "torch.Size([8, 68]) torch.Size([8, 68])\n",
              "torch.Size([8, 65]) torch.Size([8, 65])\n",
              "torch.Size([8, 72]) torch.Size([8, 72])\n",
              "torch.Size([8, 80]) torch.Size([8, 80])\n",
              "torch.Size([8, 67]) torch.Size([8, 67])\n",
              "torch.Size([8, 62]) torch.Size([8, 62])\n",
              "torch.Size([8, 75]) torch.Size([8, 75])\n",
              "torch.Size([8, 62]) torch.Size([8, 62])\n",
              "torch.Size([8, 68]) torch.Size([8, 68])\n",
              "torch.Size([8, 67]) torch.Size([8, 67])\n",
              "torch.Size([8, 77]) torch.Size([8, 77])\n",
              "torch.Size([8, 69]) torch.Size([8, 69])\n",
              "torch.Size([8, 79]) torch.Size([8, 79])\n",
              "torch.Size([8, 71]) torch.Size([8, 71])\n",
              "torch.Size([8, 66]) torch.Size([8, 66])\n",
              "torch.Size([8, 83]) torch.Size([8, 83])\n",
              "torch.Size([8, 68]) torch.Size([8, 68])\n",
              "torch.Size([8, 80]) torch.Size([8, 80])\n",
              "torch.Size([8, 71]) torch.Size([8, 71])\n",
              "torch.Size([8, 69]) torch.Size([8, 69])\n",
              "torch.Size([8, 65]) torch.Size([8, 65])\n",
              "torch.Size([8, 68]) torch.Size([8, 68])\n",
              "torch.Size([8, 60]) torch.Size([8, 60])\n",
              "torch.Size([8, 59]) torch.Size([8, 59])\n",
              "torch.Size([8, 69]) torch.Size([8, 69])\n",
              "torch.Size([8, 63]) torch.Size([8, 63])\n",
              "torch.Size([8, 65]) torch.Size([8, 65])\n",
              "torch.Size([8, 76]) torch.Size([8, 76])\n",
              "torch.Size([8, 66]) torch.Size([8, 66])\n",
              "torch.Size([8, 71]) torch.Size([8, 71])\n",
              "torch.Size([8, 91]) torch.Size([8, 91])\n",
              "torch.Size([8, 65]) torch.Size([8, 65])\n",
              "torch.Size([8, 64]) torch.Size([8, 64])\n",
              "torch.Size([8, 67]) torch.Size([8, 67])\n",
              "torch.Size([8, 66]) torch.Size([8, 66])\n",
              "torch.Size([8, 64]) torch.Size([8, 64])\n",
              "torch.Size([8, 65]) torch.Size([8, 65])\n",
              "torch.Size([8, 75]) torch.Size([8, 75])\n",
              "torch.Size([8, 89]) torch.Size([8, 89])\n",
              "torch.Size([8, 59]) torch.Size([8, 59])\n",
              "torch.Size([8, 88]) torch.Size([8, 88])\n",
              "torch.Size([8, 83]) torch.Size([8, 83])\n",
              "torch.Size([8, 83]) torch.Size([8, 83])\n",
              "torch.Size([8, 70]) torch.Size([8, 70])\n",
              "torch.Size([8, 65]) torch.Size([8, 65])\n",
              "torch.Size([8, 74]) torch.Size([8, 74])\n",
              "torch.Size([8, 76]) torch.Size([8, 76])\n",
              "torch.Size([8, 67]) torch.Size([8, 67])\n",
              "torch.Size([8, 75]) torch.Size([8, 75])\n",
              "torch.Size([8, 83]) torch.Size([8, 83])\n",
              "torch.Size([8, 69]) torch.Size([8, 69])\n",
              "torch.Size([8, 67]) torch.Size([8, 67])\n",
              "torch.Size([8, 60]) torch.Size([8, 60])\n",
              "torch.Size([8, 60]) torch.Size([8, 60])\n",
              "torch.Size([8, 66]) torch.Size([8, 66])\n",
              "torch.Size([8, 80]) torch.Size([8, 80])\n",
              "torch.Size([8, 71]) torch.Size([8, 71])\n",
              "torch.Size([8, 61]) torch.Size([8, 61])\n",
              "torch.Size([8, 58]) torch.Size([8, 58])\n",
              "torch.Size([8, 71]) torch.Size([8, 71])\n",
              "torch.Size([8, 67]) torch.Size([8, 67])\n",
              "torch.Size([8, 68]) torch.Size([8, 68])\n",
              "torch.Size([8, 63]) torch.Size([8, 63])\n",
              "torch.Size([8, 87]) torch.Size([8, 87])\n",
              "torch.Size([8, 68]) torch.Size([8, 68])\n",
              "torch.Size([8, 64]) torch.Size([8, 64])\n",
              "torch.Size([8, 68]) torch.Size([8, 68])\n",
              "torch.Size([8, 71]) torch.Size([8, 71])\n",
              "torch.Size([8, 68]) torch.Size([8, 68])\n",
              "torch.Size([8, 71]) torch.Size([8, 71])\n",
              "torch.Size([8, 61]) torch.Size([8, 61])\n",
              "torch.Size([8, 65]) torch.Size([8, 65])\n",
              "torch.Size([8, 67]) torch.Size([8, 67])\n",
              "torch.Size([8, 65]) torch.Size([8, 65])\n",
              "torch.Size([8, 64]) torch.Size([8, 64])\n",
              "torch.Size([8, 60]) torch.Size([8, 60])\n",
              "torch.Size([8, 72]) torch.Size([8, 72])\n",
              "torch.Size([8, 64]) torch.Size([8, 64])\n",
              "torch.Size([8, 70]) torch.Size([8, 70])\n",
              "torch.Size([8, 57]) torch.Size([8, 57])\n",
              "torch.Size([8, 72]) torch.Size([8, 72])\n",
              "torch.Size([8, 64]) torch.Size([8, 64])\n",
              "torch.Size([8, 68]) torch.Size([8, 68])\n",
              "torch.Size([8, 62]) torch.Size([8, 62])\n",
              "torch.Size([8, 74]) torch.Size([8, 74])\n",
              "torch.Size([8, 80]) torch.Size([8, 80])\n",
              "torch.Size([8, 68]) torch.Size([8, 68])\n",
              "torch.Size([8, 70]) torch.Size([8, 70])\n",
              "torch.Size([8, 91]) torch.Size([8, 91])\n",
              "torch.Size([8, 61]) torch.Size([8, 61])\n",
              "torch.Size([8, 66]) torch.Size([8, 66])\n",
              "torch.Size([8, 80]) torch.Size([8, 80])\n",
              "torch.Size([8, 81]) torch.Size([8, 81])\n",
              "torch.Size([8, 74]) torch.Size([8, 74])\n",
              "torch.Size([8, 82]) torch.Size([8, 82])\n",
              "torch.Size([8, 63]) torch.Size([8, 63])\n",
              "torch.Size([8, 83]) torch.Size([8, 83])\n",
              "torch.Size([8, 68]) torch.Size([8, 68])\n",
              "torch.Size([8, 67]) torch.Size([8, 67])\n",
              "torch.Size([8, 77]) torch.Size([8, 77])\n",
              "torch.Size([8, 91]) torch.Size([8, 91])\n",
              "torch.Size([8, 64]) torch.Size([8, 64])\n",
              "torch.Size([8, 61]) torch.Size([8, 61])\n",
              "torch.Size([8, 75]) torch.Size([8, 75])\n",
              "torch.Size([8, 64]) torch.Size([8, 64])\n",
              "torch.Size([8, 66]) torch.Size([8, 66])\n",
              "torch.Size([8, 78]) torch.Size([8, 78])\n",
              "torch.Size([8, 66]) torch.Size([8, 66])\n",
              "torch.Size([8, 64]) torch.Size([8, 64])\n",
              "torch.Size([8, 83]) torch.Size([8, 83])\n",
              "torch.Size([8, 66]) torch.Size([8, 66])\n",
              "torch.Size([8, 74]) torch.Size([8, 74])\n",
              "torch.Size([8, 69]) torch.Size([8, 69])\n"
            ]
          }
        ],
        "source": [
          "print(\"Train loader:\")\n",
          "for inputs, targets in train_loader:\n",
          "    print(inputs.shape, targets.shape)"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "0c8e8dd7-d46a-4cc3-8a7e-c1d31e1b4657",
        "metadata": {
          "id": "0c8e8dd7-d46a-4cc3-8a7e-c1d31e1b4657"
        },
        "source": [
          "- 上の出力からわかるように、すべてのバッチでバッチサイズは8だが、各バッチごとに長さが異なる\n",
          "- バッチ内の先頭要素（1つ目のサンプル）の `<|endoftext|>` パディングトークン（ID: 50256）が含まれているか確認する"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 26,
        "id": "21b8fd02-014f-4481-9b71-5bfee8f9dfcd",
        "metadata": {
          "colab": {
            "base_uri": "https://localhost:8080/"
          },
          "id": "21b8fd02-014f-4481-9b71-5bfee8f9dfcd",
          "outputId": "1b8ad342-2b5b-4f12-ad1a-3cb2a6c712ff"
        },
        "outputs": [
          {
            "name": "stdout",
            "output_type": "stream",
            "text": [
              "tensor([... 50256, 50256, 50256])\n"
            ]
          }
        ],
        "source": [
          "for inputs, targets in train_loader:\n",
          "    print(inputs[0])\n",
          "    break"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "5f1f3647-8971-4006-89e0-6a2a1ec1d360",
        "metadata": {
          "id": "5f1f3647-8971-4006-89e0-6a2a1ec1d360"
        },
        "source": [
          "- 同様に、ターゲットに -100 のプレースホルダトークンが含まれているかを目視確認する"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 27,
        "id": "51649ab4-1a7e-4a9e-92c5-950a24fde211",
        "metadata": {
          "colab": {
            "base_uri": "https://localhost:8080/"
          },
          "id": "51649ab4-1a7e-4a9e-92c5-950a24fde211",
          "outputId": "5e8c23f8-6a05-4c13-9f92-373b75b57ea6"
        },
        "outputs": [
          {
            "name": "stdout",
            "output_type": "stream",
            "text": [
              "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
              "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
              "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
              "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
              "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
              "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13,   -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100], device='cuda:0')\n"
            ]
          }
        ],
        "source": [
          "print(targets[0])"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "87b79a47-13f9-4d1f-87b1-3339bafaf2a3",
        "metadata": {
          "id": "87b79a47-13f9-4d1f-87b1-3339bafaf2a3"
        },
        "source": [
          "## 7.7 応答の抽出と保存"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "5a25cc88-1758-4dd0-b8bf-c044cbf2dd49",
        "metadata": {
          "id": "5a25cc88-1758-4dd0-b8bf-c044cbf2dd49"
        },
        "source": [
          "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-6.webp?1\" width=500px>"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "17510e9d-7727-4d58-ba9a-d82ec23c1427",
        "metadata": {
          "id": "17510e9d-7727-4d58-ba9a-d82ec23c1427"
        },
        "source": [
          "- このセクションでは、次のセクションでスコアリングするためにテストセットの応答を保存する"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "026e8570-071e-48a2-aa38-64d7be35f288",
        "metadata": {
          "colab": {
            "base_uri": "https://localhost:8080/",
            "height": 193
          },
          "id": "026e8570-071e-48a2-aa38-64d7be35f288",
          "outputId": "e30d3533-e1f5-4aa9-b24f-33273fc7b30e"
        },
        "outputs": [
          {
            "name": "stdout",
            "output_type": "stream",
            "text": [
              "Ollama running: True\n"
            ]
          }
        ],
        "source": [
          "import psutil\n",
          "\n",
          "def check_if_running(process_name):\n",
          "    running = False\n",
          "    for proc in psutil.process_iter([\"name\"]):\n",
          "        if process_name in proc.info[\"name\"]:\n",
          "            running = True\n",
          "            break\n",
          "    return running\n",
          "\n",
          "ollama_running = check_if_running(\"ollama\")\n",
          "\n",
          "if not ollama_running:\n",
          "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
          "print(\"Ollama running:\", check_if_running(\"ollama\"))"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "723c9b00-e3cd-4092-83c3-6e48b5cf65b0",
        "metadata": {
          "id": "723c9b00-e3cd-4092-83c3-6e48b5cf65b0"
        },
        "outputs": [],
        "source": [
          "# このセルはオプションである。ノートブックを再起動し、セクション7.7だけを実行して前のコードを再実行しないようにするためのもの\n",
          "import json\n",
          "from tqdm import tqdm\n",
          "\n",
          "file_path = \"instruction-data-with-response.json\"\n",
          "\n",
          "with open(file_path, \"r\") as file:\n",
          "    test_data = json.load(file)\n",
          "\n",
          "def format_input(entry):\n",
          "    instruction_text = (\n",
          "        f\"Below is an instruction that describes a task. \"\n",
          "        f\"Write a response that appropriately completes the request.\"\n",
          "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
          "    )\n",
          "\n",
          "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
          "\n",
          "    return instruction_text + input_text"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "b3464705-d026-4594-977f-fb357e51c3a9",
        "metadata": {
          "id": "b3464705-d026-4594-977f-fb357e51c3a9"
        },
        "source": [
          "## 7.8 モデル応答へのスコアリング"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "e2d290a8-0fb5-432e-87ed-4f6229151b9f",
        "metadata": {
          "id": "e2d290a8-0fb5-432e-87ed-4f6229151b9f"
        },
        "source": [
          "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-7.webp?1\" width=500px>"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "881d3a6e-8c90-4649-9428-d2556b4322bc",
        "metadata": {
          "id": "881d3a6e-8c90-4649-9428-d2556b4322bc"
        },
        "source": [
          "- このセクションでは、外部ツール（例: Ollama）と Llama 3 を用いて、モデル応答をスコアリングするプロセスを示す"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "d7309682-6724-4f9f-b663-d39ac596977e",
        "metadata": {
          "id": "d7309682-6724-4f9f-b663-d39ac596977e"
        },
        "source": [
          "- まず、Ollamaが実行されているか確認する"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "bc02aef3-ed3a-4a26-8d82-a91817edf758",
        "metadata": {
          "id": "bc02aef3-ed3a-4a26-8d82-a91817edf758"
        },
        "outputs": [],
        "source": [
          "import subprocess\n",
          "\n",
          "def query_model(prompt, model=\"llama3\"):\n",
          "    \"\"\"Query the Llama 3 model (or another model) via Ollama.\"\"\"\n",
          "    cmd = [\n",
          "        \"ollama\", \"run\", \"--model\", model,\n",
          "        \"--prompt\", prompt\n",
          "    ]\n",
          "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
          "    return result.stdout.strip()"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "b58f80ca-1dd7-4ab7-bd6b-c971b5f72d27",
        "metadata": {
          "id": "b58f80ca-1dd7-4ab7-bd6b-c971b5f72d27"
        },
        "source": [
          "- 次に、テストデータに含まれる各サンプルに対して、ユーザが与えた命令・入力・正解出力の3つの情報を提示し、モデル応答（`model_response`）にスコアを付けるように依頼する"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "2c27d98c-c11b-41b1-a624-88e1680d5aae",
        "metadata": {
          "id": "2c27d98c-c11b-41b1-a624-88e1680d5aae"
        },
        "outputs": [],
        "source": [
          "from tqdm import tqdm\n",
          "\n",
          "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
          "    scores = []\n",
          "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
          "        prompt = (\n",
          "            f\"Given the input `{format_input(entry)}` \"\n",
          "            f\"and correct output `{entry['output']}`, \"\n",
          "            f\"score the model response `{entry[json_key]}`\"\n",
          "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
          "            f\"Respond with the integer number only.\"\n",
          "        )\n",
          "        score = query_model(prompt, model)\n",
          "        try:\n",
          "            scores.append(int(score))\n",
          "        except ValueError:\n",
          "            print(f\"Could not convert score: {score}\")\n",
          "            continue\n",
          "\n",
          "    return scores\n",
          "\n",
          "scores = generate_model_scores(test_data, \"model_response\")\n",
          "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
          "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "407f08d5-9ada-4301-9ebc-f0533c76d3f2",
        "metadata": {
          "id": "407f08d5-9ada-4301-9ebc-f0533c76d3f2"
        },
        "source": [
          "- 本モデルは平均スコア50を上回る結果となった。これは他モデルとの比較や学習設定を変更した際の参考値になる\n",
          "- なお、OllamaはOSごとに完全な決定的挙動を示すわけではないため（本執筆時点）、若干異なる数値になる可能性がある"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "6408768b-2784-44f1-b48e-aed0c1eb9b94",
        "metadata": {
          "id": "6408768b-2784-44f1-b48e-aed0c1eb9b94"
        },
        "source": [
          "- 参考までに、オリジナルの\n",
          "  - Llama 3 8B base model はスコア 58.51 を達成\n",
          "  - Llama 3 8B instruct model はスコア 82.65 を達成"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "412d7325-284a-446c-92a1-5aa8acc52dee",
        "metadata": {
          "id": "412d7325-284a-446c-92a1-5aa8acc52dee"
        },
        "source": [
          "## 7.9 結論"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "tIbNMluCDjVM",
        "metadata": {
          "id": "tIbNMluCDjVM"
        },
        "source": [
          "### 7.9.1 次に進むには\n",
          "\n",
          "- ここで本書は最終章となる\n",
          "- これまでに、LLMアーキテクチャの実装・LLMの事前学習・ファインチューニングといったLLM開発サイクルの主要ステップをひととおり扱った\n",
          "\n",
          "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/final-overview.webp?1\" width=500px>\n",
          "\n",
          "- 本章で示したインストラクションファインチューニングの後に、オプションとして好みや指向に合わせる \"preference finetuning\" が行われる場合がある\n",
          "- Preferenceファインチューニングは特定のユーザ指向にモデルを合わせるために有用である。興味があれば [./04_preference-tuning-with-dpo](./04_preference-tuning-with-dpo) フォルダを参照してほしい\n",
          "\n",
          "- 本リポジトリには、さらに多数のボーナス資料がある。詳細はリポジトリの README にある [Bonus Material](https://github.com/rasbt/LLMs-from-scratch?tab=readme-ov-file#bonus-material) を参照してほしい\n",
          "\n",
          "### 7.9.2 変化の早い分野で最新情報を追うには\n",
          "\n",
          "- このセクションにはコードはない\n",
          "\n",
          "### 7.9.3 最後に\n",
          "\n",
          "- 本書で、一からLLMを実装し、事前学習およびファインチューニングを行うという道のりを楽しんでもらえたら幸いである\n",
          "- 個人的には、LLMをゼロから実装することがLLMの動作を理解するうえで最も効果的だと考えている。少しでも理解が深まっていれば嬉しい\n",
          "- 教育を目的とした本書だが、実用面ではより強力なLLMを使いたい場合もあるだろう。\n",
          "  - その場合、axolotl ([https://github.com/OpenAccess-AI-Collective/axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)) や LitGPT ([https://github.com/Lightning-AI/litgpt](https://github.com/Lightning-AI/litgpt)) といったツールも検討するとよい。著者もこれらの開発に携わっている"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "f9853e7f-a81a-4806-9728-be1690807185",
        "metadata": {
          "id": "f9853e7f-a81a-4806-9728-be1690807185"
        },
        "source": [
          "## まとめと要点\n",
          "\n",
          "- [./gpt_instruction_finetuning.py](./gpt_instruction_finetuning.py) スクリプトを参照。これは分類ファインチューニングのための1ファイル構成のサンプルである\n",
          "- [./ollama_evaluate.py](./ollama_evaluate.py) は、セクション7.8をもとに、JSONファイル（\"output\" と \"response\" キーを含む）をOllamaとLlama 3で評価するスタンドアロンのスクリプトである\n",
          "- [./load-finetuned-model.ipynb](./load-finetuned-model.ipynb) では、ファインチューニング後のモデルを新しいセッションで読み込む方法を示す\n",
          "- [./exercise-solutions.ipynb](./exercise-solutions.ipynb) には、練習問題の解答例がある"
        ]
      },
      {
        "cell_type": "markdown",
        "id": "b9cc51ec-e06c-4470-b626-48401a037851",
        "metadata": {
          "id": "b9cc51ec-e06c-4470-b626-48401a037851"
        },
        "source": [
          "## 今後の展望\n",
          "\n",
          "- これで本書は完了である。追加資料を探しているならば、このリポジトリに複数のボーナスセクションを追加してあるので、ぜひ確認してほしい\n",
          "- ボーナス資料の一覧は、メインREADMEの [Bonus Material](https://github.com/rasbt/LLMs-from-scratch?tab=readme-ov-file#bonus-material) セクションで確認できる\n",
          "- 特に著者が気に入っているものをいくつか挙げる:\n",
          "  1. [Direct Preference Optimization (DPO) for LLM Alignment (From Scratch)](../04_preference-tuning-with-dpo/dpo-from-scratch.ipynb): 本章のモデルをさらに人間の好みに合わせるように調整する人気のあるメカニズムを実装している\n",
          "  2. [Llama 3.2 From Scratch (A Standalone Notebook)](../../ch05/07_gpt_to_llama/standalone-llama32.ipynb): Meta AIの人気モデルLlama 3.2をゼロから実装したもので、公式の事前学習済み重みを読み込む仕組みを含む。もし追加実験を行いたいなら、各章で使った `GPTModel` を `Llama3Model` に置き換える（1:1で差し替え可能）こともできる\n",
          "  3. [Converting GPT to Llama](../../ch05/07_gpt_to_llama): GPT-2とLlama各種モデルの違いを段階的に解説したコードが含まれている\n",
          "  4. [Embedding LayersとLinear Layersの違い](../../ch02/03_bonus_embedding-vs-matmul/embeddings-and-linear-layers.ipynb): PyTorchの `Embedding` 層（LLMの入力段階で使用）とone-hotエンコーディングからのlinear layerが数学的に同等であることを示す概念的な解説\n",
          "- さらなる読書を楽しんでもらいたい"
        ]
      }
    ],
    "metadata": {
      "accelerator": "GPU",
      "colab": {
        "gpuType": "A100",
        "provenance": []
      },
      "kernelspec": {
        "display_name": "Python 3 (ipykernel)",
        "language": "python",
        "name": "python3"
      },
      "language_info": {
        "codemirror_mode": {
          "name": "ipython",
          "version": 3
        },
        "file_extension": ".py",
        "mimetype": "text/x-python",
        "name": "python",
        "nbconvert_exporter": "python",
        "pygments_lexer": "ipython3",
        "version": "3.10.16"
      }
    },
    "nbformat": 4,
    "nbformat_minor": 5
  }
    